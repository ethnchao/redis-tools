package helper

import (
	"encoding/csv"
	"errors"
	"fmt"
	"math"
	"os"
	"strconv"

	"github.com/hdt3213/rdb/bytefmt"
	"github.com/hdt3213/rdb/core"
	"github.com/hdt3213/rdb/model"
)

func prefixIt(rdbFilename string, outputFile *os.File, csvWriter *csv.Writer, topN int, maxDepth int, closeOutput bool, options ...interface{}) error {
	// decode rdb file
	rdbFile, err := os.Open(rdbFilename)
	if err != nil {
		return fmt.Errorf("open rdb %s failed, %v", rdbFilename, err)
	}
	defer func() {
		_ = rdbFile.Close()
	}()
	if closeOutput {
		defer func() {
			_ = outputFile.Close()
		}()
	}
	defer csvWriter.Flush()
	var dec decoder = core.NewDecoder(rdbFile)
	if dec, err = wrapDecoder(dec, options...); err != nil {
		return err
	}

	// prefix tree
	tree := newRadixTree()
	err = dec.Parse(func(object model.RedisObject) bool {
		key := genKey(object.GetDBIndex(), object.GetKey())
		tree.insert(key, object.GetSize())
		return true
	})
	if err != nil {
		return err
	}

	// get top list
	topListO := newToplist(topN)
	tree.traverse(func(node *radixNode, depth int) bool {
		if depth > maxDepth {
			return false
		}
		if depth <= 2 {
			// skip root and database root
			return true
		}
		topListO.add(node)
		return true
	})
	printNode := func(node *radixNode) error {
		db, key := parseNodeKey(node.fullpath)
		dbStr := strconv.Itoa(db)
		return csvWriter.Write([]string{
			dbStr,
			key,
			strconv.Itoa(node.totalSize),
			bytefmt.FormatSize(uint64(node.totalSize)),
			strconv.Itoa(node.keyCount),
		})
	}
	for _, n := range topListO.list {
		node := n.(*radixNode)
		err := printNode(node)
		if err != nil {
			return err
		}
	}
	return nil
}

// PrefixAnalyse read rdb file and find the largest N keys.
// The invoker owns output, FindBiggestKeys won't close it
func PrefixAnalyse(rdbFiles []string, topN int, maxDepth int, workDir string, workDirName string, options ...interface{}) error {
	fmt.Println("ğŸ” å¯åŠ¨å‰ç¼€åˆ†æä»»åŠ¡")
	fmt.Println("==========================================")

	if topN < 0 {
		return errors.New("âŒ é”™è¯¯: ç»“æœæ•°é‡å¿…é¡»å¤§äº0")
	} else if topN == 0 {
		topN = math.MaxInt
	}
	if maxDepth == 0 {
		maxDepth = math.MaxInt
	} else {
		maxDepth += 2 // for root(depth==1) and database root(depth==2)
	}

	fmt.Printf("ğŸ“ å·¥ä½œç›®å½•: %s\n", workDir)
	fmt.Printf("ğŸ“Š åˆ†ææ–‡ä»¶æ•°é‡: %d\n", len(rdbFiles))
	fmt.Printf("ğŸ¯ æ˜¾ç¤ºTOP %d å‰ç¼€ (æœ€å¤§æ·±åº¦: %d)\n\n",
		func() int {
			if topN == math.MaxInt {
				return -1
			} else {
				return topN
			}
		}(),
		func() int {
			if maxDepth-2 == math.MaxInt {
				return -1
			} else {
				return maxDepth - 2
			}
		}())

	var outputFiles []string // ç”¨äºæ”¶é›†ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„ï¼Œåç»­å‹ç¼©

	for i, rdbFilename := range rdbFiles {
		fmt.Printf("[%d/%d] æ­£åœ¨åˆ†æ: %s\n", i+1, len(rdbFiles), rdbFilename)

		outputPath, outputFile, err := createOutPath(rdbFilename, workDir, "-prefix.csv", false)
		if err != nil {
			return fmt.Errorf("âŒ åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤±è´¥: %v", err)
		}

		// æ”¶é›†è¾“å‡ºæ–‡ä»¶è·¯å¾„
		outputFiles = append(outputFiles, outputPath)

		// å†™å…¥CSVå¤´éƒ¨
		_, err = outputFile.WriteString("æ•°æ®åº“,å‰ç¼€,KEYå¤§å°,KEYå¤§å°[K/M/G],ä¸ªæ•°\n")
		if err != nil {
			return fmt.Errorf("âŒ å†™å…¥CSVå¤´éƒ¨å¤±è´¥: %v", err)
		}

		csvWriter := csv.NewWriter(outputFile)
		err = prefixIt(rdbFilename, outputFile, csvWriter, topN, maxDepth, true, options...)
		if err != nil {
			return fmt.Errorf("âŒ åˆ†æRDBæ–‡ä»¶å¤±è´¥: %v", err)
		}

		fmt.Printf("  âœ… å®Œæˆ -> %s\n", outputPath)
	}

	fmt.Println("\nğŸ“¦ æ­£åœ¨æ‰“åŒ…æŠ¥å‘Šæ–‡ä»¶...")
	// å‹ç¼©è¾“å‡ºæ–‡ä»¶
	if len(outputFiles) > 0 {
		zipPath := generateZipName(workDir, workDirName)
		err := compressFiles(outputFiles, zipPath)
		if err != nil {
			fmt.Printf("âŒ å‹ç¼©å¤±è´¥: %v\n", err)
		} else {
			fmt.Printf("âœ… å‹ç¼©å®Œæˆ: %s\n", zipPath)
			// æ¸…ç†åŸå§‹æ–‡ä»¶
			cleanupFiles(outputFiles)
		}
	}

	fmt.Println("==========================================")
	fmt.Printf("ğŸ‰ å‰ç¼€åˆ†æä»»åŠ¡å®Œæˆï¼Œå…±åˆ†æ %d ä¸ªRDBæ–‡ä»¶\n", len(rdbFiles))
	return nil
}
